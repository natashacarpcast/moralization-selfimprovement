{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_8794/2445656005.py:2: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/final_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "#Open data\n",
    "data = pd.read_csv(\"data/final_data.csv\")\n",
    "\n",
    "#Import moral words separately\n",
    "from liwc_moral_words import liwc_moral\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to get morality words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moral_words(text, word_list):\n",
    "    '''\n",
    "    Tokenizes text into list of words and keeps only those from the \n",
    "    dictionary\n",
    "\n",
    "    Inputs:\n",
    "      - text (str): cleaned text from subreddit\n",
    "      - word_list (list of strings): words to assess\n",
    "\n",
    "    Outputs:\n",
    "      (list): list of morality words\n",
    "    '''\n",
    "    words_liwc = []\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in word_list:\n",
    "            words_liwc.append(word)\n",
    "\n",
    "    return words_liwc\n",
    "\n",
    "def count_words(data, word_list):\n",
    "    '''\n",
    "    Create a dictionary that maps moral words with their frequency on the entire\n",
    "    corpus\n",
    "\n",
    "    Inputs:\n",
    "      - data (series): cleaned_text column\n",
    "\n",
    "    Outputs:\n",
    "      - (dict): dictionary mapping words with their frequencies\n",
    "\n",
    "    '''\n",
    "\n",
    "    moral_words_counts = {}\n",
    "\n",
    "    for entry in data:\n",
    "        row_words = get_moral_words(entry, word_list)\n",
    "\n",
    "        for word in row_words:\n",
    "            moral_words_counts[word] = moral_words_counts.get(word, 0) + 1\n",
    "\n",
    "    sorted_dict= dict(sorted(moral_words_counts.items(), key=lambda item: item[1],\n",
    "                                                                  reverse=True))\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get LIWC moral words frequencies for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by topic and apply the functions to each group\n",
    "topic_dictionaries_liwc = {}\n",
    "for topic, group in data.groupby('dominant_topic'):\n",
    "    text_series = group['cleaned_text']\n",
    "    topic_dictionaries_liwc[topic] = count_words(text_series, liwc_moral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wrong': 106,\n",
       " 'honest': 33,\n",
       " 'fault': 24,\n",
       " 'useful': 24,\n",
       " 'lazy': 22,\n",
       " 'deserve': 21,\n",
       " 'shame': 21,\n",
       " 'judge': 14,\n",
       " 'blame': 11,\n",
       " 'laziness': 10,\n",
       " 'excuse': 9,\n",
       " 'judging': 9,\n",
       " 'judged': 8,\n",
       " 'decent': 7,\n",
       " 'conscience': 7,\n",
       " 'honesty': 6,\n",
       " 'blaming': 6,\n",
       " 'competent': 5,\n",
       " 'forgive': 5,\n",
       " 'fake': 5,\n",
       " 'ignorant': 5,\n",
       " 'brave': 5,\n",
       " 'useless': 5,\n",
       " 'selfish': 4,\n",
       " 'blamed': 4,\n",
       " 'dumb': 3,\n",
       " 'disrespect': 3,\n",
       " 'shaming': 3,\n",
       " 'worthwhile': 3,\n",
       " 'commend': 3,\n",
       " 'cheated': 3,\n",
       " 'courage': 3,\n",
       " 'faults': 2,\n",
       " 'offensive': 2,\n",
       " 'ridiculously': 2,\n",
       " 'worthy': 2,\n",
       " 'evil': 2,\n",
       " 'inappropriate': 2,\n",
       " 'righteous': 2,\n",
       " 'excuses': 2,\n",
       " 'forgiving': 2,\n",
       " 'braver': 2,\n",
       " 'ethical': 2,\n",
       " 'deserves': 2,\n",
       " 'honor': 2,\n",
       " 'moral': 2,\n",
       " 'cheating': 2,\n",
       " 'ridiculous': 2,\n",
       " 'pussies': 1,\n",
       " 'deserved': 1,\n",
       " 'unfair': 1,\n",
       " 'unreasonable': 1,\n",
       " 'overbearing': 1,\n",
       " 'disrespectful': 1,\n",
       " 'decently': 1,\n",
       " 'injustice': 1,\n",
       " 'reprehensible': 1,\n",
       " 'truthfully': 1,\n",
       " 'treacherous': 1,\n",
       " 'nerd': 1,\n",
       " 'mistreated': 1,\n",
       " 'wronged': 1,\n",
       " 'trustworthy': 1,\n",
       " 'disapproving': 1,\n",
       " 'cruel': 1,\n",
       " 'promiscuous': 1,\n",
       " 'worthless': 1,\n",
       " 'absurd': 1,\n",
       " 'courageous': 1,\n",
       " 'vengeance': 1,\n",
       " 'forgiven': 1,\n",
       " 'ideal': 1,\n",
       " 'disrespected': 1,\n",
       " 'petty': 1,\n",
       " 'prejudice': 1,\n",
       " 'faking': 1,\n",
       " 'admonishing': 1,\n",
       " 'misuse': 1,\n",
       " 'misusing': 1,\n",
       " 'vain': 1}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_dictionaries_liwc['Topic 9']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get average positive emotion and negative emotion scores for top 10 words in each topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a column with the LIWC moral words for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"moral_words\"] = data[\"cleaned_text\"].apply(lambda x: get_moral_words(x, liwc_moral))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'created', 'author', 'score', 'num_comments', 'link',\n",
       "       'cleaned_text', 'word_count', 'type', 'link_id', 'year', 'month',\n",
       "       'Segment_1', 'emo_pos', 'emo_neg', 'emo_anx', 'emo_anger', 'emo_sad',\n",
       "       'moral', 'Segment', 'Care_Virtue', 'Care_Vice', 'Fairness_Virtue',\n",
       "       'Fairness_Vice', 'Loyalty_Virtue', 'Loyalty_Vice', 'Authority_Virtue',\n",
       "       'Authority_Vice', 'Sanctity_Virtue', 'Sanctity_Vice',\n",
       "       'topic_distribution', 'dominant_topic', 'prob_topic', 'Care_total',\n",
       "       'Fairness_total', 'Loyalty_total', 'Authority_total', 'Sanctity_total',\n",
       "       'Virtue_total', 'Vice_total', 'Foundations_total_score', 'moral_words'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_emotion(df, topic,  dict):\n",
    "\n",
    "    #Create dictionaries to store emotions scores\n",
    "    avg_pos_emotion = {}\n",
    "    avg_neg_emotion = {}\n",
    "    avg_moral = {}\n",
    "\n",
    "    #Filter df based on topic\n",
    "    topic_df = df[df.dominant_topic == topic]\n",
    "\n",
    "    #Get dict for topic\n",
    "    topic_dict = dict[topic]\n",
    "\n",
    "    for idx, row in topic_df.iterrows():\n",
    "        for word in row[\"moral_words\"]:\n",
    "            avg_pos_emotion[word] = avg_pos_emotion.get(word, 0) + row[\"emo_pos\"]\n",
    "            avg_neg_emotion[word] = avg_neg_emotion.get(word, 0) + row[\"emo_neg\"]\n",
    "            avg_moral[word] = avg_moral.get(word,0) + row[\"moral\"]\n",
    "\n",
    "    for word, value in avg_pos_emotion.items():\n",
    "        avg_pos_emotion[word] = value / topic_dict[word] \n",
    "\n",
    "    for word, value in avg_neg_emotion.items():\n",
    "        avg_neg_emotion[word] = value / topic_dict[word]\n",
    "\n",
    "    for word, value in avg_moral.items():\n",
    "        avg_moral[word] = value / topic_dict[word]    \n",
    "\n",
    "    return avg_pos_emotion, avg_neg_emotion, avg_moral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1_words_emopos, topic1_words_emoneg, topic1_words_moral = get_avg_emotion(data, \"Topic 1\", topic_dictionaries_liwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2_words_emopos, topic2_words_emoneg, topic2_words_moral = get_avg_emotion(data, \"Topic 2\", topic_dictionaries_liwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic3_words_emopos, topic3_words_emoneg, topic3_words_moral = get_avg_emotion(data, \"Topic 3\", topic_dictionaries_liwc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4_words_emopos, topic4_words_emoneg, topic4_words_moral = get_avg_emotion(data, \"Topic 4\", topic_dictionaries_liwc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic5_words_emopos, topic5_words_emoneg, topic5_words_moral = get_avg_emotion(data, \"Topic 5\", topic_dictionaries_liwc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic6_words_emopos, topic6_words_emoneg, topic6_words_moral = get_avg_emotion(data, \"Topic 6\", topic_dictionaries_liwc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic7_words_emopos, topic7_words_emoneg, topic7_words_moral = get_avg_emotion(data, \"Topic 7\", topic_dictionaries_liwc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic8_words_emopos, topic8_words_emoneg, topic8_words_moral = get_avg_emotion(data, \"Topic 8\", topic_dictionaries_liwc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic9_words_emopos, topic9_words_emoneg, topic9_words_moral = get_avg_emotion(data, \"Topic 9\", topic_dictionaries_liwc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, create a dataframe for each topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emotion_df(avg_pos_emotion, avg_neg_emotion, avg_moral, moral_dict):\n",
    "    # Create a dictionary with words as keys and their corresponding pos, neg scores and counts as values\n",
    "    data = {\n",
    "        'word': list(avg_pos_emotion.keys()),\n",
    "        'count': [moral_dict.get(word, 0) for word in avg_pos_emotion],  # Use moral_dict to get word count\n",
    "        'pos_score': [avg_pos_emotion.get(word, 0) for word in avg_pos_emotion],\n",
    "        'neg_score': [avg_neg_emotion.get(word, 0) for word in avg_neg_emotion],\n",
    "        'moral_score': [avg_moral.get(word, 0) for word in avg_moral]\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic1 = create_emotion_df(topic1_words_emopos, topic1_words_emoneg, topic1_words_moral, topic_dictionaries_liwc[\"Topic 1\"])\n",
    "topic1[\"topic\"] = \"Topic 1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2 = create_emotion_df(topic2_words_emopos, topic2_words_emoneg, topic2_words_moral, topic_dictionaries_liwc[\"Topic 2\"])\n",
    "topic2[\"topic\"] = \"Topic 2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic3 = create_emotion_df(topic3_words_emopos, topic3_words_emoneg, topic3_words_moral, topic_dictionaries_liwc[\"Topic 3\"])\n",
    "topic3[\"topic\"] = \"Topic 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic4 = create_emotion_df(topic4_words_emopos, topic4_words_emoneg, topic4_words_moral, topic_dictionaries_liwc[\"Topic 4\"])\n",
    "topic4[\"topic\"] = \"Topic 4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic5 = create_emotion_df(topic5_words_emopos, topic5_words_emoneg, topic5_words_moral, topic_dictionaries_liwc[\"Topic 5\"])\n",
    "topic5[\"topic\"] = \"Topic 5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic6 = create_emotion_df(topic6_words_emopos, topic6_words_emoneg, topic6_words_moral, topic_dictionaries_liwc[\"Topic 6\"])\n",
    "topic6[\"topic\"] = \"Topic 6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic7 = create_emotion_df(topic7_words_emopos, topic7_words_emoneg, topic7_words_moral, topic_dictionaries_liwc[\"Topic 7\"])\n",
    "topic7[\"topic\"] = \"Topic 7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic8 = create_emotion_df(topic8_words_emopos, topic8_words_emoneg, topic8_words_moral, topic_dictionaries_liwc[\"Topic 8\"])\n",
    "topic8[\"topic\"] = \"Topic 8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic9 = create_emotion_df(topic9_words_emopos, topic9_words_emoneg, topic9_words_moral, topic_dictionaries_liwc[\"Topic 9\"])\n",
    "topic9[\"topic\"] = \"Topic 9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>moral_score</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excuses</td>\n",
       "      <td>310</td>\n",
       "      <td>0.695710</td>\n",
       "      <td>0.538129</td>\n",
       "      <td>0.924548</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>excuse</td>\n",
       "      <td>189</td>\n",
       "      <td>0.558307</td>\n",
       "      <td>0.584021</td>\n",
       "      <td>0.839101</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ideal</td>\n",
       "      <td>249</td>\n",
       "      <td>0.720281</td>\n",
       "      <td>0.461084</td>\n",
       "      <td>0.157349</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>honest</td>\n",
       "      <td>256</td>\n",
       "      <td>0.758008</td>\n",
       "      <td>0.594766</td>\n",
       "      <td>0.667188</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wrong</td>\n",
       "      <td>604</td>\n",
       "      <td>0.729553</td>\n",
       "      <td>0.685248</td>\n",
       "      <td>0.907517</td>\n",
       "      <td>Topic 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>cheat</td>\n",
       "      <td>103</td>\n",
       "      <td>0.979612</td>\n",
       "      <td>0.977476</td>\n",
       "      <td>2.269029</td>\n",
       "      <td>Topic 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>fault</td>\n",
       "      <td>136</td>\n",
       "      <td>0.955221</td>\n",
       "      <td>0.917279</td>\n",
       "      <td>1.088529</td>\n",
       "      <td>Topic 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>wrong</td>\n",
       "      <td>266</td>\n",
       "      <td>0.764624</td>\n",
       "      <td>0.965150</td>\n",
       "      <td>0.905526</td>\n",
       "      <td>Topic 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>decent</td>\n",
       "      <td>111</td>\n",
       "      <td>0.737568</td>\n",
       "      <td>0.636937</td>\n",
       "      <td>0.752973</td>\n",
       "      <td>Topic 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>wrong</td>\n",
       "      <td>106</td>\n",
       "      <td>0.494340</td>\n",
       "      <td>3.269340</td>\n",
       "      <td>1.174623</td>\n",
       "      <td>Topic 9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  count  pos_score  neg_score  moral_score    topic\n",
       "1     excuses    310   0.695710   0.538129     0.924548  Topic 1\n",
       "2      excuse    189   0.558307   0.584021     0.839101  Topic 1\n",
       "3       ideal    249   0.720281   0.461084     0.157349  Topic 1\n",
       "6      honest    256   0.758008   0.594766     0.667188  Topic 1\n",
       "9       wrong    604   0.729553   0.685248     0.907517  Topic 1\n",
       "...       ...    ...        ...        ...          ...      ...\n",
       "1018    cheat    103   0.979612   0.977476     2.269029  Topic 6\n",
       "1020    fault    136   0.955221   0.917279     1.088529  Topic 6\n",
       "1255    wrong    266   0.764624   0.965150     0.905526  Topic 7\n",
       "1272   decent    111   0.737568   0.636937     0.752973  Topic 7\n",
       "1503    wrong    106   0.494340   3.269340     1.174623  Topic 9\n",
       "\n",
       "[72 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df = pd.concat([topic1, topic2, topic3, topic4, topic5, topic6, topic7, topic8, topic9], ignore_index=True)\n",
    "filtered_df = combined_df[combined_df[\"count\"] >= 100]\n",
    "filtered_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_csv(\"data/moralwords_bytopic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72.000000\n",
       "mean      1.009467\n",
       "std       0.329163\n",
       "min       0.494340\n",
       "25%       0.774304\n",
       "50%       0.974843\n",
       "75%       1.148755\n",
       "max       2.666842\n",
       "Name: pos_score, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.pos_score.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    72.000000\n",
       "mean      1.009807\n",
       "std       0.433630\n",
       "min       0.348219\n",
       "25%       0.704589\n",
       "50%       0.942976\n",
       "75%       1.192239\n",
       "max       3.269340\n",
       "Name: neg_score, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.neg_score.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
