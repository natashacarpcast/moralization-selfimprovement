{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Rl21PXH6KbF"
      },
      "source": [
        "This notebook is downloaded and adapted from the GitHub repo of the authors of MoralBERT (https://github.com/vjosapreniqi/MoralBERT/tree/main)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3OAsdTCV32m"
      },
      "source": [
        "#Â Predicting Moral Values in Text\n",
        "### This Code offers predicting moral values from the MoralBERT weights deployad in Hugging Face."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9VkZKG1WD6u"
      },
      "outputs": [],
      "source": [
        "# Libraries:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from huggingface_hub import PyTorchModelHubMixin\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24gZZeD8YfR",
        "outputId": "17bf6749-5ec1-4a55-bf7d-40923b0d0480"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nxHGA-ok8s7l",
        "outputId": "6e1df817-e8b5-458e-fd5e-afcf6cb11f7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to create documents for analyses"
      ],
      "metadata": {
        "id": "q4GOx__CCMSc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsjTA32D8twL"
      },
      "outputs": [],
      "source": [
        "selfimprovement = \"/content/drive/My Drive/UChicago/Tesis/cleaned_data1.csv\"\n",
        "investing = \"/content/drive/My Drive/UChicago/Tesis/investing_cleaned.csv\"\n",
        "homeowners = \"/content/drive/My Drive/UChicago/Tesis/homeowners_cleaned.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsWPDDxG82Tk"
      },
      "outputs": [],
      "source": [
        "def create_documents(path, n):\n",
        "  df = pd.read_csv(path)\n",
        "\n",
        "  # Sort based on the \"score\" column in descending order\n",
        "  sorted_df = df.sort_values(by='score', ascending=False)\n",
        "\n",
        "  # Select the top rows\n",
        "  top_df = sorted_df.head(n)\n",
        "\n",
        "  # Create list of documents\n",
        "\n",
        "  lst_docs = top_df['cleaned_text'].tolist()\n",
        "\n",
        "  return lst_docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pw13n59Z9GAf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bae0c89-d156-470e-f755-727a143032ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-8a8999c82b42>:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n",
            "<ipython-input-38-8a8999c82b42>:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df = pd.read_csv(path)\n"
          ]
        }
      ],
      "source": [
        "selfimprovement_list = create_documents(selfimprovement, 200)\n",
        "investing_list = create_documents(investing, 200)\n",
        "homeowners_list = create_documents(homeowners, 200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNd3ddD6gCSl"
      },
      "outputs": [],
      "source": [
        "# BERT model and tokenizer:\n",
        "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B8MknQBWN-B"
      },
      "outputs": [],
      "source": [
        "class MyModel(\n",
        "    nn.Module,\n",
        "    PyTorchModelHubMixin,\n",
        "    # optionally, you can add metadata which gets pushed to the model card\n",
        "    # repo_url=\"your-repo-url\",\n",
        "    pipeline_tag=\"text-classification\",\n",
        "    license=\"mit\",\n",
        "):\n",
        "    def __init__(self, bert_model, moral_label=2):\n",
        "\n",
        "        super(MyModel, self).__init__()\n",
        "        self.bert = bert_model\n",
        "        bert_dim = 768\n",
        "        self.invariant_trans = nn.Linear(768, 768)\n",
        "        self.moral_classification = nn.Sequential(nn.Linear(768,768),\n",
        "                                                      nn.ReLU(),\n",
        "                                                      nn.Linear(768, moral_label))\n",
        "\n",
        "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
        "        pooled_output = self.bert(input_ids,\n",
        "                                token_type_ids = token_type_ids,\n",
        "                                attention_mask = attention_mask).last_hidden_state[:,0,:]\n",
        "\n",
        "\n",
        "        pooled_output = self.invariant_trans(pooled_output)\n",
        "\n",
        "\n",
        "        logits = self.moral_classification(pooled_output)\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6NWvkBHWV7H"
      },
      "outputs": [],
      "source": [
        "def preprocessing(input_text, tokenizer):\n",
        "    '''\n",
        "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "    '''\n",
        "    return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 150,\n",
        "                        padding = 'max_length',\n",
        "                        return_attention_mask = True,\n",
        "                        return_token_type_ids = True,  # Add this line\n",
        "                        return_tensors = 'pt',\n",
        "                        truncation=True\n",
        "                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJ6Tf3frf78a"
      },
      "outputs": [],
      "source": [
        "# the list of Moral (MFT) values\n",
        "mft_values = [\"care\", \"harm\", \"fairness\", \"cheating\", \"loyalty\", \"betrayal\",\n",
        "              \"authority\", \"subversion\", \"purity\", \"degradation\"]\n",
        "\n",
        "# function to load the model, predict the score, and return the second value\n",
        "def get_model_score(sentence, mft):\n",
        "    repo_name = f\"vjosap/moralBERT-predict-{mft}-in-text\"\n",
        "\n",
        "    # loading the model\n",
        "    model = MyModel.from_pretrained(repo_name, bert_model=bert_model)\n",
        "\n",
        "    # preprocessing the text\n",
        "    encodeds = preprocessing(sentence, tokenizer)\n",
        "\n",
        "    # predicting the mft score\n",
        "    output = model(**encodeds)\n",
        "    score = F.softmax(output, dim=1)\n",
        "\n",
        "    # extracting and return the second value from the tensor\n",
        "    mft_value = score[0, 1].item()\n",
        "\n",
        "    return mft_value\n",
        "\n",
        "def analyze_corpus(sentences, corpus_name):\n",
        "  # initialising a list to accumulate the results\n",
        "  results = []\n",
        "\n",
        "  # sequential execution of predictions\n",
        "  for sentence in sentences:\n",
        "      # dictionary to store scores for the current sentence\n",
        "      sentence_scores = {\"sentence\": sentence}\n",
        "\n",
        "      # iterate through each MFT model and get the score\n",
        "      for mft in mft_values:\n",
        "          sentence_scores[mft] = get_model_score(sentence, mft)\n",
        "\n",
        "      results.append(sentence_scores)\n",
        "\n",
        "  results_df = pd.DataFrame(results)\n",
        "\n",
        "  # save the DataFrame to a CSV file\n",
        "  results_df.to_csv(\"/content/drive/My Drive/UChicago/Tesis/MoralBERTresults-{}.csv\".format(corpus_name), index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_corpus(selfimprovement_list, \"selfimprovement\")"
      ],
      "metadata": {
        "id": "BZ2-pZzCQcU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_corpus(investing_list, \"investing\")"
      ],
      "metadata": {
        "id": "UX4OzV_BD-8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_corpus(homeowners_list, \"homeowners\")"
      ],
      "metadata": {
        "id": "tz5sPd51QbYO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}