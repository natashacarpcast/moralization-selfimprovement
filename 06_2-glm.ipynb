{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1843/1586172768.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/engineered_morality.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'created', 'author', 'score',\n",
       "       'num_comments', 'link', 'cleaned_text', 'word_count', 'type', 'link_id',\n",
       "       'year', 'month', 'Segment_1', 'emo_pos', 'emo_neg', 'emo_anx',\n",
       "       'emo_anger', 'emo_sad', 'moral', 'Segment', 'Care_Virtue', 'Care_Vice',\n",
       "       'Fairness_Virtue', 'Fairness_Vice', 'Loyalty_Virtue', 'Loyalty_Vice',\n",
       "       'Authority_Virtue', 'Authority_Vice', 'Sanctity_Virtue',\n",
       "       'Sanctity_Vice', 'Care_total', 'Fairness_total', 'Loyalty_total',\n",
       "       'Authority_total', 'Sanctity_total', 'Virtue_total', 'Vice_total',\n",
       "       'Foundations_total_score', 'Subreddit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/engineered_morality.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC moral score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         0.154164\n",
      "investing          0.191849\n",
      "selfimprovement    0.320543\n",
      "Name: moral, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_means = data.groupby('Subreddit')['moral'].mean()\n",
    "print(sub_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe variance of moral scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         0.241381\n",
      "investing          0.297560\n",
      "selfimprovement    0.474709\n",
      "Name: moral, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_variances = data.groupby('Subreddit')['moral'].var()\n",
    "print(sub_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically check differences in variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 11379.1347\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Split the data by subreddit\n",
    "group1 = data[data['Subreddit'] == 'selfimprovement']['moral']\n",
    "group2 = data[data['Subreddit'] == 'homeowners']['moral']\n",
    "group3 = data[data['Subreddit'] == 'investing']['moral']\n",
    "\n",
    "# Levene's test for equal variances\n",
    "stat, p_value = levene(group1, group2, group3)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogeneous variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable: 1 if morality score > 0, else 0. This is to try to model the likelihood of containing *any* moral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moral_present'] = (data['moral'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check binary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Count  Percentage\n",
      "moral_present                     \n",
      "0              1219464       80.53\n",
      "1               294777       19.47\n"
     ]
    }
   ],
   "source": [
    "# Get value counts \n",
    "counts = data['moral_present'].value_counts()\n",
    "\n",
    "# Convert to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution by subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moral_present        0      1\n",
      "Subreddit                    \n",
      "homeowners       86.95  13.05\n",
      "investing        83.78  16.22\n",
      "selfimprovement  70.95  29.05\n"
     ]
    }
   ],
   "source": [
    "subreddit_percent = data.groupby('Subreddit')['moral_present'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "subreddit_percent = subreddit_percent.round(2)\n",
    "print(subreddit_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the subreddit column a categorical variable that will be used as a categorical predictor (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Subreddit'] = data['subreddit'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model --> Is moral language present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          moral_present   No. Observations:              1514241\n",
      "Model:                            GLM   Df Residuals:                  1514238\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -7.2397e+05\n",
      "Date:                Fri, 04 Apr 2025   Deviance:                   1.4479e+06\n",
      "Time:                        21:25:25   Pearson chi2:                 1.51e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02920\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -1.8963      0.004   -452.868      0.000      -1.905      -1.888\n",
      "C(Subreddit)[T.investing]           0.2541      0.006     44.832      0.000       0.243       0.265\n",
      "C(Subreddit)[T.selfimprovement]     1.0033      0.005    192.745      0.000       0.993       1.013\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model = smf.glm(\n",
    "    formula='moral_present ~ C(Subreddit)',\n",
    "    data=data,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 is a covariance estimator that adjusts for \n",
    "                          #heteroskedasticity\n",
    "\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GLM Marginal Effects        \n",
      "=====================================\n",
      "Dep. Variable:          moral_present\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "C(Subreddit)[T.investing]           0.0386      0.001     44.861      0.000       0.037       0.040\n",
      "C(Subreddit)[T.selfimprovement]     0.1525      0.001    197.367      0.000       0.151       0.154\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mfx = logit_model.get_margeff()\n",
    "print(mfx.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities of showing moral language, to make it more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the GLM output\n",
    "intercept = -1.8963  # Homeowners (baseline)\n",
    "coef_investing = 0.2541\n",
    "coef_selfimprovement = 1.0033"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log-odds for each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Odds:\n",
      "Homeowners: -1.8963\n",
      "Investing: -1.6422\n",
      "Selfimprovement: -0.893\n"
     ]
    }
   ],
   "source": [
    "logit_homeowners = intercept \n",
    "logit_investing = intercept + coef_investing\n",
    "logit_selfimprovement = intercept + coef_selfimprovement\n",
    "\n",
    "print(\"Log-Odds:\")\n",
    "print(f\"Homeowners: {logit_homeowners}\")\n",
    "print(f\"Investing: {logit_investing}\")\n",
    "print(f\"Selfimprovement: {logit_selfimprovement}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert log-odds with predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Probabilities:\n",
      "Homeowners: 0.1305\n",
      "Investing: 0.1622\n",
      "Selfimprovement: 0.2905\n"
     ]
    }
   ],
   "source": [
    "# Logistic function\n",
    "def logit_to_prob(logit):\n",
    "    return np.exp(logit) / (1 + np.exp(logit))\n",
    "\n",
    "# Apply to each group\n",
    "prob_homeowners = logit_to_prob(logit_homeowners)\n",
    "prob_investing = logit_to_prob(logit_investing)\n",
    "prob_selfimprovement = logit_to_prob(logit_selfimprovement)\n",
    "\n",
    "print(\"\\nPredicted Probabilities:\")\n",
    "print(f\"Homeowners: {prob_homeowners:.4f}\")\n",
    "print(f\"Investing: {prob_investing:.4f}\")\n",
    "print(f\"Selfimprovement: {prob_selfimprovement:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Foundations Dictionary Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obseve means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         1.409286\n",
      "investing          1.582064\n",
      "selfimprovement    1.916615\n",
      "Name: Foundations_total_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_means_mfd = data.groupby('Subreddit')['Foundations_total_score'].mean()\n",
    "print(sub_means_mfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         2.551364\n",
      "investing          3.071992\n",
      "selfimprovement    3.109352\n",
      "Name: Foundations_total_score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_variances_mfd = data.groupby('Subreddit')['Foundations_total_score'].var()\n",
    "print(sub_variances_mfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levene tests to check differences in variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 1371.0129\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Split the data by subreddit\n",
    "group1 = data[data['Subreddit'] == 'selfimprovement']['Foundations_total_score']\n",
    "group2 = data[data['Subreddit'] == 'homeowners']['Foundations_total_score']\n",
    "group3 = data[data['Subreddit'] == 'investing']['Foundations_total_score']\n",
    "\n",
    "# Levene's test for equal variances\n",
    "stat, p_value = levene(group1, group2, group3)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances are different here too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable: 1 if morality score > 0, else 0. This is to try to model the likelihood of containing *any* moral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moral_present_mfd'] = (data['Foundations_total_score'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check binary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  Percentage\n",
      "moral_present_mfd                     \n",
      "1                  1061487        70.1\n",
      "0                   452754        29.9\n"
     ]
    }
   ],
   "source": [
    "# Get value counts \n",
    "counts = data['moral_present_mfd'].value_counts()\n",
    "\n",
    "# Convert to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution by subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moral_present_mfd      0      1\n",
      "Subreddit                      \n",
      "homeowners         35.80  64.20\n",
      "investing          33.22  66.78\n",
      "selfimprovement    20.76  79.24\n"
     ]
    }
   ],
   "source": [
    "subreddit_percent = data.groupby('Subreddit')['moral_present_mfd'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "subreddit_percent = subreddit_percent.round(2)\n",
    "print(subreddit_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:      moral_present_mfd   No. Observations:              1514241\n",
      "Model:                            GLM   Df Residuals:                  1514238\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -9.0751e+05\n",
      "Date:                Sun, 06 Apr 2025   Deviance:                   1.8150e+06\n",
      "Time:                        12:04:00   Pearson chi2:                 1.51e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02116\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                           0.5841      0.003    198.511      0.000       0.578       0.590\n",
      "C(Subreddit)[T.investing]           0.1139      0.004     27.158      0.000       0.106       0.122\n",
      "C(Subreddit)[T.selfimprovement]     0.7556      0.005    166.327      0.000       0.747       0.765\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model_mfd = smf.glm(\n",
    "    formula='moral_present_mfd ~ C(Subreddit)',\n",
    "    data=data,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 again for heteroskedasticity\n",
    "\n",
    "print(logit_model_mfd.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GLM Marginal Effects        \n",
      "=====================================\n",
      "Dep. Variable:      moral_present_mfd\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "C(Subreddit)[T.investing]           0.0234      0.001     27.182      0.000       0.022       0.025\n",
      "C(Subreddit)[T.selfimprovement]     0.1551      0.001    171.228      0.000       0.153       0.157\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mfx = logit_model_mfd.get_margeff()\n",
    "print(mfx.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities of showing moral language, to make it more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the GLM output\n",
    "intercept = 0.5841 #Homeowners (baseline)\n",
    "coef_investing = 0.1139\n",
    "coef_selfimprovement = 0.7556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log-odds for each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Odds:\n",
      "Homeowners: 0.5841\n",
      "Investing: 0.698\n",
      "Selfimprovement: 1.3397000000000001\n"
     ]
    }
   ],
   "source": [
    "logit_homeowners = intercept \n",
    "logit_investing = intercept + coef_investing\n",
    "logit_selfimprovement = intercept + coef_selfimprovement\n",
    "\n",
    "print(\"Log-Odds:\")\n",
    "print(f\"Homeowners: {logit_homeowners}\")\n",
    "print(f\"Investing: {logit_investing}\")\n",
    "print(f\"Selfimprovement: {logit_selfimprovement}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert log-odds with predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Probabilities:\n",
      "Homeowners: 0.6420\n",
      "Investing: 0.6677\n",
      "Selfimprovement: 0.7924\n"
     ]
    }
   ],
   "source": [
    "# Logistic function\n",
    "def logit_to_prob(logit):\n",
    "    return np.exp(logit) / (1 + np.exp(logit))\n",
    "\n",
    "# Apply to each group\n",
    "prob_homeowners = logit_to_prob(logit_homeowners)\n",
    "prob_investing = logit_to_prob(logit_investing)\n",
    "prob_selfimprovement = logit_to_prob(logit_selfimprovement)\n",
    "\n",
    "print(\"\\nPredicted Probabilities:\")\n",
    "print(f\"Homeowners: {prob_homeowners:.4f}\")\n",
    "print(f\"Investing: {prob_investing:.4f}\")\n",
    "print(f\"Selfimprovement: {prob_selfimprovement:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to both the LIWC's moral dimension and The Moral Foundations dictionary, the subreddit r/selfimprovement has a higher probability of showing moral language."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
