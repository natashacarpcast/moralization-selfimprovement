{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_4683/1586172768.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/engineered_morality.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'created', 'author', 'score',\n",
       "       'num_comments', 'link', 'cleaned_text', 'word_count', 'type', 'link_id',\n",
       "       'year', 'month', 'Segment_1', 'emo_pos', 'emo_neg', 'emo_anx',\n",
       "       'emo_anger', 'emo_sad', 'moral', 'Segment', 'Care_Virtue', 'Care_Vice',\n",
       "       'Fairness_Virtue', 'Fairness_Vice', 'Loyalty_Virtue', 'Loyalty_Vice',\n",
       "       'Authority_Virtue', 'Authority_Vice', 'Sanctity_Virtue',\n",
       "       'Sanctity_Vice', 'Care_total', 'Fairness_total', 'Loyalty_total',\n",
       "       'Authority_total', 'Sanctity_total', 'Virtue_total', 'Vice_total',\n",
       "       'Foundations_total_score', 'Subreddit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/engineered_morality.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC moral score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe variance of moral scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         0.241381\n",
      "investing          0.297560\n",
      "selfimprovement    0.474709\n",
      "Name: moral, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_variances = data.groupby('Subreddit')['moral'].var()\n",
    "print(sub_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable: 1 if morality score > 0, else 0. This is to try to model the likelihood of containing *any* moral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moral_present'] = (data['moral'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check binary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Count  Percentage\n",
      "moral_present                     \n",
      "0              1219464       80.53\n",
      "1               294777       19.47\n"
     ]
    }
   ],
   "source": [
    "# Get value counts \n",
    "counts = data['moral_present'].value_counts()\n",
    "\n",
    "# Convert to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution by subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moral_present        0      1\n",
      "Subreddit                    \n",
      "homeowners       86.95  13.05\n",
      "investing        83.78  16.22\n",
      "selfimprovement  70.95  29.05\n"
     ]
    }
   ],
   "source": [
    "subreddit_percent = data.groupby('Subreddit')['moral_present'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "subreddit_percent = subreddit_percent.round(2)\n",
    "print(subreddit_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the subreddit column a categorical variable that will be used as a categorical predictor (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Subreddit'] = data['subreddit'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          moral_present   No. Observations:              1514241\n",
      "Model:                            GLM   Df Residuals:                  1514238\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -7.2397e+05\n",
      "Date:                Fri, 04 Apr 2025   Deviance:                   1.4479e+06\n",
      "Time:                        21:25:25   Pearson chi2:                 1.51e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02920\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================\n",
      "                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "Intercept                          -1.8963      0.004   -452.868      0.000      -1.905      -1.888\n",
      "C(Subreddit)[T.investing]           0.2541      0.006     44.832      0.000       0.243       0.265\n",
      "C(Subreddit)[T.selfimprovement]     1.0033      0.005    192.745      0.000       0.993       1.013\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model = smf.glm(\n",
    "    formula='moral_present ~ C(Subreddit)',\n",
    "    data=data,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 is a covariance estimator that adjusts for \n",
    "                          #heteroskedasticity\n",
    "\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GLM Marginal Effects        \n",
      "=====================================\n",
      "Dep. Variable:          moral_present\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "===================================================================================================\n",
      "                                     dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------------------\n",
      "C(Subreddit)[T.investing]           0.0386      0.001     44.861      0.000       0.037       0.040\n",
      "C(Subreddit)[T.selfimprovement]     0.1525      0.001    197.367      0.000       0.151       0.154\n",
      "===================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mfx = logit_model.get_margeff()\n",
    "print(mfx.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities of showing moral language, to make it more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the GLM output\n",
    "intercept = -1.8963  # Homeowners (baseline)\n",
    "coef_investing = 0.2541\n",
    "coef_selfimprovement = 1.0033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Odds:\n",
      "Homeowners: -1.8963\n",
      "Investing: -1.6422\n",
      "Selfimprovement: -0.893\n"
     ]
    }
   ],
   "source": [
    "# Compute log-odds for each subreddit\n",
    "logit_homeowners = intercept \n",
    "logit_investing = intercept + coef_investing\n",
    "logit_selfimprovement = intercept + coef_selfimprovement\n",
    "\n",
    "print(\"Log-Odds:\")\n",
    "print(f\"Homeowners: {logit_homeowners}\")\n",
    "print(f\"Investing: {logit_investing}\")\n",
    "print(f\"Selfimprovement: {logit_selfimprovement}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Probabilities:\n",
      "Homeowners: 0.1305\n",
      "Investing: 0.1622\n",
      "Selfimprovement: 0.2905\n"
     ]
    }
   ],
   "source": [
    "# Convert log-odds with predicted probabilities\n",
    "# Logistic function\n",
    "def logit_to_prob(logit):\n",
    "    return np.exp(logit) / (1 + np.exp(logit))\n",
    "\n",
    "# Apply to each group\n",
    "prob_homeowners = logit_to_prob(logit_homeowners)\n",
    "prob_investing = logit_to_prob(logit_investing)\n",
    "prob_selfimprovement = logit_to_prob(logit_selfimprovement)\n",
    "\n",
    "print(\"\\nPredicted Probabilities:\")\n",
    "print(f\"Homeowners: {prob_homeowners:.4f}\")\n",
    "print(f\"Investing: {prob_investing:.4f}\")\n",
    "print(f\"Selfimprovement: {prob_selfimprovement:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
