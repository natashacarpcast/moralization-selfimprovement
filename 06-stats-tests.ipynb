{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import numpy as np\n",
    "from scipy.stats import levene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1542/1586172768.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/engineered_morality.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'created', 'author', 'score',\n",
       "       'num_comments', 'link', 'cleaned_text', 'word_count', 'type', 'link_id',\n",
       "       'year', 'month', 'Segment_1', 'i', 'you', 'shehe', 'they', 'emo_pos',\n",
       "       'emo_neg', 'emo_anx', 'emo_anger', 'emo_sad', 'moral', 'Segment',\n",
       "       'Care_Virtue', 'Care_Vice', 'Fairness_Virtue', 'Fairness_Vice',\n",
       "       'Loyalty_Virtue', 'Loyalty_Vice', 'Authority_Virtue', 'Authority_Vice',\n",
       "       'Sanctity_Virtue', 'Sanctity_Vice', 'Care_total', 'Fairness_total',\n",
       "       'Loyalty_total', 'Authority_total', 'Sanctity_total', 'Virtue_total',\n",
       "       'Vice_total', 'Foundations_total_score', 'Subreddit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/engineered_morality.csv\")\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Question 1: Is moral language present in discussions about self-improvement?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIWC moral score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         0.154216\n",
      "investing          0.193725\n",
      "selfimprovement    0.330980\n",
      "Name: moral, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_means = data.groupby('Subreddit')['moral'].mean()\n",
    "print(sub_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe variance of moral scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         0.243729\n",
      "investing          0.303137\n",
      "selfimprovement    0.490467\n",
      "Name: moral, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub_variances = data.groupby('Subreddit')['moral'].var()\n",
    "print(sub_variances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistically check differences in variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 12522.9065\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Split the data by subreddit\n",
    "group1 = data[data['Subreddit'] == 'selfimprovement']['moral']\n",
    "group2 = data[data['Subreddit'] == 'homeowners']['moral']\n",
    "group3 = data[data['Subreddit'] == 'investing']['moral']\n",
    "\n",
    "# Levene's test for equal variances\n",
    "stat, p_value = levene(group1, group2, group3)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogeneous variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable: 1 if morality score > 0, else 0. This is to try to model the likelihood of containing *any* moral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moral_present'] = (data['moral'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check binary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Count  Percentage\n",
      "moral_present                     \n",
      "0              1211271        80.3\n",
      "1               297194        19.7\n"
     ]
    }
   ],
   "source": [
    "# Get value counts \n",
    "counts = data['moral_present'].value_counts()\n",
    "\n",
    "# Convert to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution by subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moral_present        0      1\n",
      "Subreddit                    \n",
      "homeowners       86.98  13.02\n",
      "investing        83.79  16.21\n",
      "selfimprovement  70.25  29.75\n"
     ]
    }
   ],
   "source": [
    "subreddit_percent = data.groupby('Subreddit')['moral_present'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "subreddit_percent = subreddit_percent.round(2)\n",
    "print(subreddit_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the subreddit column a categorical variable that will be used as a categorical predictor (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Subreddit'] = data['Subreddit'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model --> Is moral language present?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:          moral_present   No. Observations:              1508465\n",
      "Model:                            GLM   Df Residuals:                  1508462\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -7.2422e+05\n",
      "Date:                Sun, 06 Apr 2025   Deviance:                   1.4484e+06\n",
      "Time:                        17:27:00   Pearson chi2:                 1.51e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.03176\n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================================================\n",
      "                                                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                             -0.8593      0.003   -279.595      0.000      -0.865      -0.853\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.homeowners]    -1.0399      0.005   -199.572      0.000      -1.050      -1.030\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.investing]     -0.7834      0.005   -159.646      0.000      -0.793      -0.774\n",
      "======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model = smf.glm(\n",
    "    formula='moral_present ~ C(Subreddit, Treatment(reference=\"selfimprovement\"))',\n",
    "    data=data,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 is a covariance estimator that adjusts for \n",
    "                          #heteroskedasticity\n",
    "\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GLM Marginal Effects        \n",
      "=====================================\n",
      "Dep. Variable:          moral_present\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "======================================================================================================================================\n",
      "                                                                        dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.homeowners]    -0.1590      0.001   -204.931      0.000      -0.161      -0.158\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.investing]     -0.1198      0.001   -162.795      0.000      -0.121      -0.118\n",
      "======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mfx = logit_model.get_margeff()\n",
    "print(mfx.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities of showing moral language, to make it more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the GLM output\n",
    "intercept = -0.8593  # Selfimprovement (baseline)\n",
    "coef_homeowners = -1.0399\n",
    "coef_investing = -0.7834"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log-odds for each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Odds:\n",
      "Selfimprovement: -0.8593\n",
      "Homeowners: -1.8992\n",
      "Investing: -1.6427\n"
     ]
    }
   ],
   "source": [
    "logit_selfimprovement = intercept \n",
    "logit_homeowners = intercept + coef_homeowners\n",
    "logit_investing = intercept + coef_investing\n",
    "\n",
    "\n",
    "print(\"Log-Odds:\")\n",
    "print(f\"Selfimprovement: {logit_selfimprovement}\")\n",
    "print(f\"Homeowners: {logit_homeowners}\")\n",
    "print(f\"Investing: {logit_investing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert log-odds with predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Probabilities:\n",
      "Selfimprovement: 0.2975\n",
      "Homeowners: 0.1302\n",
      "Investing: 0.1621\n"
     ]
    }
   ],
   "source": [
    "# Logistic function\n",
    "def logit_to_prob(logit):\n",
    "    return np.exp(logit) / (1 + np.exp(logit))\n",
    "\n",
    "# Apply to each group\n",
    "prob_selfimprovement = logit_to_prob(logit_selfimprovement)\n",
    "prob_homeowners = logit_to_prob(logit_homeowners)\n",
    "prob_investing = logit_to_prob(logit_investing)\n",
    "\n",
    "\n",
    "print(\"\\nPredicted Probabilities:\")\n",
    "print(f\"Selfimprovement: {prob_selfimprovement:.4f}\")\n",
    "print(f\"Homeowners: {prob_homeowners:.4f}\")\n",
    "print(f\"Investing: {prob_investing:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moral Foundations Dictionary Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obseve means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         1.446587\n",
      "investing          1.652188\n",
      "selfimprovement    1.958449\n",
      "Name: Foundations_total_score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1779/3206419513.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sub_means_mfd = data.groupby('Subreddit')['Foundations_total_score'].mean()\n"
     ]
    }
   ],
   "source": [
    "sub_means_mfd = data.groupby('Subreddit')['Foundations_total_score'].mean()\n",
    "print(sub_means_mfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subreddit\n",
      "homeowners         2.641538\n",
      "investing          3.255616\n",
      "selfimprovement    3.195955\n",
      "Name: Foundations_total_score, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1779/3568421637.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  sub_variances_mfd = data.groupby('Subreddit')['Foundations_total_score'].var()\n"
     ]
    }
   ],
   "source": [
    "sub_variances_mfd = data.groupby('Subreddit')['Foundations_total_score'].var()\n",
    "print(sub_variances_mfd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Levene tests to check differences in variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 1558.6439\n",
      "p-value: 0.0000\n"
     ]
    }
   ],
   "source": [
    "# Split the data by subreddit\n",
    "group1 = data[data['Subreddit'] == 'selfimprovement']['Foundations_total_score']\n",
    "group2 = data[data['Subreddit'] == 'homeowners']['Foundations_total_score']\n",
    "group3 = data[data['Subreddit'] == 'investing']['Foundations_total_score']\n",
    "\n",
    "# Levene's test for equal variances\n",
    "stat, p_value = levene(group1, group2, group3)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variances are different here too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a binary variable: 1 if morality score > 0, else 0. This is to try to model the likelihood of containing *any* moral language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['moral_present_mfd'] = (data['Foundations_total_score'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check binary distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Count  Percentage\n",
      "moral_present_mfd                     \n",
      "1                  1069640       70.91\n",
      "0                   438825       29.09\n"
     ]
    }
   ],
   "source": [
    "# Get value counts \n",
    "counts = data['moral_present_mfd'].value_counts()\n",
    "\n",
    "# Convert to percentages\n",
    "percentages = counts / counts.sum() * 100\n",
    "\n",
    "summary_df = pd.DataFrame({\n",
    "    'Count': counts,\n",
    "    'Percentage': percentages.round(2)\n",
    "})\n",
    "\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution by subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moral_present_mfd      0      1\n",
      "Subreddit                      \n",
      "homeowners         35.04  64.96\n",
      "investing          32.06  67.94\n",
      "selfimprovement    20.28  79.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1779/3463568615.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  subreddit_percent = data.groupby('Subreddit')['moral_present_mfd'].value_counts(normalize=True).unstack().fillna(0) * 100\n"
     ]
    }
   ],
   "source": [
    "subreddit_percent = data.groupby('Subreddit')['moral_present_mfd'].value_counts(normalize=True).unstack().fillna(0) * 100\n",
    "subreddit_percent = subreddit_percent.round(2)\n",
    "print(subreddit_percent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:      moral_present_mfd   No. Observations:              1508465\n",
      "Model:                            GLM   Df Residuals:                  1508462\n",
      "Model Family:                Binomial   Df Model:                            2\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -8.9414e+05\n",
      "Date:                Sun, 06 Apr 2025   Deviance:                   1.7883e+06\n",
      "Time:                        17:33:28   Pearson chi2:                 1.51e+06\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02023\n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================================================\n",
      "                                                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                              1.3688      0.003    391.727      0.000       1.362       1.376\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.homeowners]    -0.7516      0.005   -163.934      0.000      -0.761      -0.743\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.investing]     -0.6178      0.005   -133.755      0.000      -0.627      -0.609\n",
      "======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model_mfd = smf.glm(\n",
    "    formula='moral_present_mfd ~ C(Subreddit, Treatment(reference=\"selfimprovement\"))',\n",
    "    data=data,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 again for heteroskedasticity\n",
    "\n",
    "print(logit_model_mfd.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marginal effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         GLM Marginal Effects        \n",
      "=====================================\n",
      "Dep. Variable:      moral_present_mfd\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "======================================================================================================================================\n",
      "                                                                        dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------------------------------------------------------\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.homeowners]    -0.1520      0.001   -168.534      0.000      -0.154      -0.150\n",
      "C(Subreddit, Treatment(reference=\"selfimprovement\"))[T.investing]     -0.1249      0.001   -136.124      0.000      -0.127      -0.123\n",
      "======================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "mfx = logit_model_mfd.get_margeff()\n",
    "print(mfx.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get probabilities of showing moral language, to make it more intuitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients from the GLM output\n",
    "intercept = 1.3688 #Selfimprovement (baseline)\n",
    "coef_homeowners = -0.7516\n",
    "coef_investing = -0.6178\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute log-odds for each subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-Odds:\n",
      "Selfimprovement: 1.3688\n",
      "Homeowners: 0.6172\n",
      "Investing: 0.751\n"
     ]
    }
   ],
   "source": [
    "logit_selfimprovement = intercept \n",
    "logit_homeowners = intercept + coef_homeowners\n",
    "logit_investing = intercept + coef_investing\n",
    "\n",
    "print(\"Log-Odds:\")\n",
    "print(f\"Selfimprovement: {logit_selfimprovement}\")\n",
    "print(f\"Homeowners: {logit_homeowners}\")\n",
    "print(f\"Investing: {logit_investing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert log-odds with predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guide: https://sebastiansauer.github.io/convert_logit2prob/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Probabilities:\n",
      "Selfimprovement: 0.7972\n",
      "Homeowners: 0.6496\n",
      "Investing: 0.6794\n"
     ]
    }
   ],
   "source": [
    "# Logistic function\n",
    "def logit_to_prob(logit):\n",
    "    return np.exp(logit) / (1 + np.exp(logit))\n",
    "\n",
    "# Apply to each group\n",
    "prob_selfimprovement = logit_to_prob(logit_selfimprovement)\n",
    "prob_homeowners = logit_to_prob(logit_homeowners)\n",
    "prob_investing = logit_to_prob(logit_investing)\n",
    "\n",
    "\n",
    "print(\"\\nPredicted Probabilities:\")\n",
    "print(f\"Selfimprovement: {prob_selfimprovement:.4f}\")\n",
    "print(f\"Homeowners: {prob_homeowners:.4f}\")\n",
    "print(f\"Investing: {prob_investing:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion RQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to both the LIWC's moral dimension and The Moral Foundations dictionary, the subreddit r/selfimprovement has a higher probability of showing moral language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RQ 3. How is the use of moral language associated with emotions in the context of self-improvement?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506574, 45)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfimpr = data[data.Subreddit == \"selfimprovement\"]\n",
    "selfimpr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1542/344381257.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selfimpr['moral_present'] = np.where(selfimpr['moral'] > 0, 'present', 'not present')\n",
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1542/344381257.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selfimpr['moral_present'] = selfimpr['moral_present'].astype('category')\n"
     ]
    }
   ],
   "source": [
    "selfimpr['moral_present'] = np.where(selfimpr['moral'] > 0, 'present', 'not present')\n",
    "selfimpr['moral_present'] = selfimpr['moral_present'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "moral_present\n",
       "not present    355876\n",
       "present        150698\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfimpr.moral_present.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General emo_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Levene’s test statistic: 10.8353\n",
      "p-value: 0.0010\n"
     ]
    }
   ],
   "source": [
    "# Split the data by morality presence\n",
    "group1 = selfimpr[selfimpr['moral_present'] == 'not present']['emo_neg']\n",
    "group2 = selfimpr[selfimpr['moral_present'] == 'present']['emo_neg']\n",
    "\n",
    "# Levene's test for equal variances\n",
    "stat, p_value = levene(group1, group2)\n",
    "\n",
    "print(f\"Levene’s test statistic: {stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heterogeneous variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create binary label for negative emotion score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_6386/2487086695.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selfimpr['emo_neg_present'] = (selfimpr['emo_neg'] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "selfimpr['emo_neg_present'] = (selfimpr['emo_neg'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emo_neg_present\n",
       "1    286026\n",
       "0    220548\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfimpr.emo_neg_present.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        emo_neg_present   No. Observations:               506574\n",
      "Model:                            GLM   Df Residuals:                   506572\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -3.3893e+05\n",
      "Date:                Sun, 06 Apr 2025   Deviance:                   6.7786e+05\n",
      "Time:                        21:41:15   Pearson chi2:                 5.07e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.03093\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================================================\n",
      "                                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                           0.0325      0.003      9.695      0.000       0.026       0.039\n",
      "C(moral_present, Treatment(reference=\"not present\"))[T.present]     0.8056      0.007    123.240      0.000       0.793       0.818\n",
      "===================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model = smf.glm(\n",
    "    formula='emo_neg_present ~ C(moral_present, Treatment(reference=\"not present\"))',\n",
    "    data=selfimpr,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  # HC1 is a covariance estimator that adjusts for \n",
    "                          #heteroskedasticity\n",
    "\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2380389194051817"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = 0.8056\n",
    "np.exp(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posts with moral language are approximately 2.23 times more likely to express anger language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary label for anger score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1542/98923382.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  selfimpr['emo_ang_present'] = (selfimpr['emo_anger'] > 0).astype(int)\n"
     ]
    }
   ],
   "source": [
    "selfimpr['emo_ang_present'] = (selfimpr['emo_anger'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emo_ang_present\n",
       "0    427030\n",
       "1     79544\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selfimpr.emo_ang_present.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:        emo_ang_present   No. Observations:               506574\n",
      "Model:                            GLM   Df Residuals:                   506572\n",
      "Model Family:                Binomial   Df Model:                            1\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:            -2.1340e+05\n",
      "Date:                Sat, 26 Apr 2025   Deviance:                   4.2680e+05\n",
      "Time:                        19:38:19   Pearson chi2:                 5.07e+05\n",
      "No. Iterations:                     5   Pseudo R-squ. (CS):            0.02652\n",
      "Covariance Type:                  HC1                                         \n",
      "===================================================================================================================================\n",
      "                                                                      coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------------------------------------\n",
      "Intercept                                                          -2.0222      0.005   -387.589      0.000      -2.032      -2.012\n",
      "C(moral_present, Treatment(reference=\"not present\"))[T.present]     0.9331      0.008    118.079      0.000       0.918       0.949\n",
      "===================================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "logit_model = smf.glm(\n",
    "    formula='emo_ang_present ~ C(moral_present, Treatment(reference=\"not present\"))',\n",
    "    data=selfimpr,\n",
    "    family=sm.families.Binomial()\n",
    ").fit(cov_type='HC1')  \n",
    "\n",
    "print(logit_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate odds ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.542378346979088"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff = 0.9331\n",
    "np.exp(coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posts with moral language are approximately 2.54 times more likely to express anger language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
