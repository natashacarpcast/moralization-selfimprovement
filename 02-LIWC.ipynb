{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the data for Tableau exploratory data analysis from results of LIWC software."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1853/3194509895.py:1: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  selfimprovement = pd.read_csv(\"data/liwc+mfd2-results.csv\")\n",
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1853/3194509895.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  investing = pd.read_csv(\"data_to_compare/liwc/investing-liwc+mfd2.csv\")\n",
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_1853/3194509895.py:3: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  homeowners = pd.read_csv(\"data_to_compare/liwc/homeowners-liwc+mfd2.csv\")\n"
     ]
    }
   ],
   "source": [
    "selfimprovement = pd.read_csv(\"data/liwc+mfd2-results.csv\")\n",
    "investing = pd.read_csv(\"data_to_compare/liwc/investing-liwc+mfd2.csv\")\n",
    "homeowners = pd.read_csv(\"data_to_compare/liwc/homeowners-liwc+mfd2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe proportions of moral language across subreddits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get total sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call shape method to get shape of dataframe and select the number of rows\n",
    "total_si = selfimprovement.shape[0]\n",
    "total_i = investing.shape[0]\n",
    "total_h = homeowners.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of posts with moralization score higher than 0.25 (the LIWC's reported mean for their corpus of Reddit + other sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_si = selfimprovement[selfimprovement.moral > 0.25]\n",
    "moral_i = investing[investing.moral > 0.25]\n",
    "moral_h = homeowners[homeowners.moral > 0.25]\n",
    "\n",
    "#Repear workflow to get number of rows\n",
    "moral_si_n = moral_si.shape[0]\n",
    "moral_i_n = moral_i.shape[0]\n",
    "moral_h_n = moral_h.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate proportion of moralization language across the three subreddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_si = (moral_si_n / total_si) * 100\n",
    "percentage_i = (moral_i_n / total_i) * 100\n",
    "percentage_h = (moral_h_n / total_h) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion of moralized posts in the r/selfimprovement subreddit: 27.36%\n",
      "Proportion of moralized posts in the r/investing subreddit:15.55%\n",
      "Proportion of moralized posts in the r/homeowners subreddit:12.67%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Proportion of moralized posts in the r/selfimprovement subreddit: {percentage_si:.2f}%\")\n",
    "print(f\"Proportion of moralized posts in the r/investing subreddit:{percentage_i:.2f}%\")\n",
    "print(f\"Proportion of moralized posts in the r/homeowners subreddit:{percentage_h:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering with foundations scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some feature engineering to create combined scores for each foundation, and combined scores for virtue and vice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "\n",
    "    # Calculate total for each foundation\n",
    "    df[\"Care_total\"] = df[\"Care_Virtue\"] + df[\"Care_Vice\"]\n",
    "    df[\"Fairness_total\"] = df[\"Fairness_Virtue\"] + df[\"Fairness_Vice\"]\n",
    "    df[\"Loyalty_total\"] = df[\"Loyalty_Virtue\"] + df[\"Loyalty_Vice\"]\n",
    "    df[\"Authority_total\"] = df[\"Authority_Virtue\"] + df[\"Authority_Vice\"]\n",
    "    df[\"Sanctity_total\"] = df[\"Sanctity_Virtue\"] + df[\"Sanctity_Vice\"]\n",
    "\n",
    "    # Vice and virtue scores\n",
    "    df[\"Virtue_total\"] = (df[\"Care_Virtue\"] + df[\"Fairness_Virtue\"] \n",
    "                          + df[\"Loyalty_Virtue\"] + df[\"Authority_Virtue\"] \n",
    "                          + df[\"Sanctity_Virtue\"])\n",
    "    \n",
    "    df[\"Vice_total\"] = (df[\"Care_Vice\"] + df[\"Fairness_Vice\"] \n",
    "                    + df[\"Loyalty_Vice\"] + df[\"Authority_Vice\"] \n",
    "                    + df[\"Sanctity_Vice\"])\n",
    "    \n",
    "    # Overall total score across all foundations\n",
    "    df[\"Foundations_total_score\"] = (\n",
    "        df[\"Care_total\"] + df[\"Fairness_total\"] + df[\"Loyalty_total\"] +\n",
    "        df[\"Authority_total\"] + df[\"Sanctity_total\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfimprovement2 = feature_engineering(selfimprovement)\n",
    "investing2 = feature_engineering(investing)\n",
    "homeowners2 = feature_engineering(homeowners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one single df to use in Tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfimprovement2[\"Subreddit\"] = \"selfimprovement\"\n",
    "investing2[\"Subreddit\"] = \"investing\"\n",
    "homeowners2[\"Subreddit\"] = \"homeowners\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reddits = pd.concat([selfimprovement2, investing2, homeowners2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>created</th>\n",
       "      <th>author</th>\n",
       "      <th>score</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>link</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>word_count</th>\n",
       "      <th>type</th>\n",
       "      <th>...</th>\n",
       "      <th>Sanctity_Vice</th>\n",
       "      <th>Care_total</th>\n",
       "      <th>Fairness_total</th>\n",
       "      <th>Loyalty_total</th>\n",
       "      <th>Authority_total</th>\n",
       "      <th>Sanctity_total</th>\n",
       "      <th>Virtue_total</th>\n",
       "      <th>Vice_total</th>\n",
       "      <th>Foundations_total_score</th>\n",
       "      <th>Subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hk5r2</td>\n",
       "      <td>2011-05-25 17:27</td>\n",
       "      <td>u/[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>https://www.reddit.com/r/selfimprovement/comme...</td>\n",
       "      <td>i had an appointment today with the dentist ov...</td>\n",
       "      <td>65</td>\n",
       "      <td>submission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>selfimprovement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>iqimz</td>\n",
       "      <td>2011-07-15 11:15</td>\n",
       "      <td>u/dustinsmusings</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.reddit.com/r/selfimprovement/comme...</td>\n",
       "      <td>i created this site several months ago and i s...</td>\n",
       "      <td>116</td>\n",
       "      <td>submission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.59</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.45</td>\n",
       "      <td>selfimprovement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pfzt5</td>\n",
       "      <td>2012-02-08 01:40</td>\n",
       "      <td>u/aeoz</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>https://www.reddit.com/r/selfimprovement/comme...</td>\n",
       "      <td>hello everyone  i have recently took over this...</td>\n",
       "      <td>194</td>\n",
       "      <td>submission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.06</td>\n",
       "      <td>selfimprovement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>pk714</td>\n",
       "      <td>2012-02-10 19:16</td>\n",
       "      <td>u/[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.reddit.com/r/selfimprovement/comme...</td>\n",
       "      <td>i grew up with body dysmorphia eating disorder...</td>\n",
       "      <td>583</td>\n",
       "      <td>submission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.23</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.68</td>\n",
       "      <td>3.42</td>\n",
       "      <td>selfimprovement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>q0q8x</td>\n",
       "      <td>2012-02-22 03:24</td>\n",
       "      <td>u/[deleted]</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>https://www.reddit.com/r/selfimprovement/comme...</td>\n",
       "      <td>i have to ask when do you get to a point where...</td>\n",
       "      <td>558</td>\n",
       "      <td>submission</td>\n",
       "      <td>...</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.62</td>\n",
       "      <td>2.52</td>\n",
       "      <td>selfimprovement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514236</th>\n",
       "      <td>502528</td>\n",
       "      <td>kfrkhs5</td>\n",
       "      <td>2023-12-31 17:29</td>\n",
       "      <td>u/Earl_your_friend</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/homeowners/comments/1...</td>\n",
       "      <td>i lived next to a guy who sold and bought scap...</td>\n",
       "      <td>198</td>\n",
       "      <td>comment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.02</td>\n",
       "      <td>3.05</td>\n",
       "      <td>homeowners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514237</th>\n",
       "      <td>502529</td>\n",
       "      <td>kfrl16r</td>\n",
       "      <td>2023-12-31 17:33</td>\n",
       "      <td>u/UntypicalCouple</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/homeowners/comments/1...</td>\n",
       "      <td>you do realize that not all businesses can be ...</td>\n",
       "      <td>62</td>\n",
       "      <td>comment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.23</td>\n",
       "      <td>1.61</td>\n",
       "      <td>4.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.84</td>\n",
       "      <td>homeowners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514238</th>\n",
       "      <td>502530</td>\n",
       "      <td>kfrm79i</td>\n",
       "      <td>2023-12-31 17:41</td>\n",
       "      <td>u/blockneighborradio</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/homeowners/comments/1...</td>\n",
       "      <td>the neighbor isnt going to do anything stupid ...</td>\n",
       "      <td>51</td>\n",
       "      <td>comment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>homeowners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514239</th>\n",
       "      <td>502531</td>\n",
       "      <td>kfrmlea</td>\n",
       "      <td>2023-12-31 17:43</td>\n",
       "      <td>u/chof2018</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/homeowners/comments/1...</td>\n",
       "      <td>i was this guy running a landscaping business ...</td>\n",
       "      <td>137</td>\n",
       "      <td>comment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.19</td>\n",
       "      <td>homeowners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514240</th>\n",
       "      <td>502532</td>\n",
       "      <td>kfrokme</td>\n",
       "      <td>2023-12-31 17:57</td>\n",
       "      <td>u/shaneacton1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/homeowners/comments/1...</td>\n",
       "      <td>its free to dig and lay brick youre a lowintel...</td>\n",
       "      <td>63</td>\n",
       "      <td>comment</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.17</td>\n",
       "      <td>homeowners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1514241 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0       id           created                author  score  \\\n",
       "0                 0    hk5r2  2011-05-25 17:27           u/[deleted]      1   \n",
       "1                 1    iqimz  2011-07-15 11:15      u/dustinsmusings      3   \n",
       "2                 2    pfzt5  2012-02-08 01:40                u/aeoz      6   \n",
       "3                 3    pk714  2012-02-10 19:16           u/[deleted]      1   \n",
       "4                 4    q0q8x  2012-02-22 03:24           u/[deleted]      1   \n",
       "...             ...      ...               ...                   ...    ...   \n",
       "1514236      502528  kfrkhs5  2023-12-31 17:29    u/Earl_your_friend      1   \n",
       "1514237      502529  kfrl16r  2023-12-31 17:33     u/UntypicalCouple      8   \n",
       "1514238      502530  kfrm79i  2023-12-31 17:41  u/blockneighborradio      2   \n",
       "1514239      502531  kfrmlea  2023-12-31 17:43            u/chof2018      2   \n",
       "1514240      502532  kfrokme  2023-12-31 17:57         u/shaneacton1     -1   \n",
       "\n",
       "         num_comments                                               link  \\\n",
       "0                 3.0  https://www.reddit.com/r/selfimprovement/comme...   \n",
       "1                 0.0  https://www.reddit.com/r/selfimprovement/comme...   \n",
       "2                 4.0  https://www.reddit.com/r/selfimprovement/comme...   \n",
       "3                 0.0  https://www.reddit.com/r/selfimprovement/comme...   \n",
       "4                 0.0  https://www.reddit.com/r/selfimprovement/comme...   \n",
       "...               ...                                                ...   \n",
       "1514236           NaN  https://www.reddit.com/r/homeowners/comments/1...   \n",
       "1514237           NaN  https://www.reddit.com/r/homeowners/comments/1...   \n",
       "1514238           NaN  https://www.reddit.com/r/homeowners/comments/1...   \n",
       "1514239           NaN  https://www.reddit.com/r/homeowners/comments/1...   \n",
       "1514240           NaN  https://www.reddit.com/r/homeowners/comments/1...   \n",
       "\n",
       "                                              cleaned_text  word_count  \\\n",
       "0        i had an appointment today with the dentist ov...          65   \n",
       "1        i created this site several months ago and i s...         116   \n",
       "2        hello everyone  i have recently took over this...         194   \n",
       "3        i grew up with body dysmorphia eating disorder...         583   \n",
       "4        i have to ask when do you get to a point where...         558   \n",
       "...                                                    ...         ...   \n",
       "1514236  i lived next to a guy who sold and bought scap...         198   \n",
       "1514237  you do realize that not all businesses can be ...          62   \n",
       "1514238  the neighbor isnt going to do anything stupid ...          51   \n",
       "1514239  i was this guy running a landscaping business ...         137   \n",
       "1514240  its free to dig and lay brick youre a lowintel...          63   \n",
       "\n",
       "               type  ... Sanctity_Vice  Care_total  Fairness_total  \\\n",
       "0        submission  ...          0.00        0.00            0.00   \n",
       "1        submission  ...          0.00        2.59            0.00   \n",
       "2        submission  ...          0.00        2.06            0.00   \n",
       "3        submission  ...          0.17        2.23            0.17   \n",
       "4        submission  ...          0.54        1.44            0.00   \n",
       "...             ...  ...           ...         ...             ...   \n",
       "1514236     comment  ...          0.51        0.51            0.51   \n",
       "1514237     comment  ...          0.00        0.00            0.00   \n",
       "1514238     comment  ...          0.00        0.00            0.00   \n",
       "1514239     comment  ...          0.00        0.00            0.73   \n",
       "1514240     comment  ...          0.00        0.00            0.00   \n",
       "\n",
       "         Loyalty_total  Authority_total  Sanctity_total  Virtue_total  \\\n",
       "0                 0.00             0.00            0.00          0.00   \n",
       "1                 0.86             0.00            0.00          3.45   \n",
       "2                 0.00             0.00            0.00          2.06   \n",
       "3                 0.34             0.00            0.68          2.74   \n",
       "4                 0.00             0.00            1.08          0.90   \n",
       "...                ...              ...             ...           ...   \n",
       "1514236           0.00             1.52            0.51          2.03   \n",
       "1514237           0.00             3.23            1.61          4.84   \n",
       "1514238           0.00             0.00            0.00          0.00   \n",
       "1514239           0.00             1.46            0.00          2.19   \n",
       "1514240           0.00             0.00            3.17          3.17   \n",
       "\n",
       "         Vice_total  Foundations_total_score        Subreddit  \n",
       "0              0.00                     0.00  selfimprovement  \n",
       "1              0.00                     3.45  selfimprovement  \n",
       "2              0.00                     2.06  selfimprovement  \n",
       "3              0.68                     3.42  selfimprovement  \n",
       "4              1.62                     2.52  selfimprovement  \n",
       "...             ...                      ...              ...  \n",
       "1514236        1.02                     3.05       homeowners  \n",
       "1514237        0.00                     4.84       homeowners  \n",
       "1514238        0.00                     0.00       homeowners  \n",
       "1514239        0.00                     2.19       homeowners  \n",
       "1514240        0.00                     3.17       homeowners  \n",
       "\n",
       "[1514241 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reddits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reddits.to_csv(\"datavis/engineered_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure correct parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5q/yq3hk8g1793ckqmn2n3xpr6c0000gn/T/ipykernel_3299/657471035.py:1: DtypeWarning: Columns (11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  saved_csv = pd.read_csv(\"datavis/engineered_data.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1514241, 40)\n",
      "(1514241, 41)\n"
     ]
    }
   ],
   "source": [
    "saved_csv = pd.read_csv(\"datavis/engineered_data.csv\")\n",
    "\n",
    "print(all_reddits.shape)\n",
    "print(saved_csv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore morality words frequence LIWC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create list with LIWC moral words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_moral = [\n",
    "    \"absurd\", \"absurdity\", \"absurdities\", \"accusation\", \"accusations\", \"accusative\", \"accuse\",\n",
    "    \"accuses\", \"accusing\", \"admirable\", \"admonish\", \"admonished\", \"admonishing\", \"admonishes\",\n",
    "    \"admonishment\", \"adulterate\", \"adulterated\", \"adulterating\", \"adulterates\", \"adulteration\",\n",
    "    \"adulterer\", \"adulterers\", \"adulteress\", \"adulteresses\", \"adulteries\", \"adulterous\",\n",
    "    \"adultery\", \"amoral\", \"amorality\", \"arrogant\", \"betray\", \"betrayed\", \"betraying\",\n",
    "    \"betrays\", \"betrayal\", \"betrayer\", \"bigot\", \"bigots\", \"bigoted\", \"bigotry\", \"blame\",\n",
    "    \"blames\", \"blamed\", \"blaming\", \"brave\", \"bravely\", \"braver\", \"bravest\", \"buffoon\",\n",
    "    \"buffoons\", \"buffoonish\", \"careless\", \"carelessness\", \"carpetbag\", \"carpetbags\",\n",
    "    \"censure\", \"censured\", \"censures\", \"censuring\", \"chastise\", \"chastised\", \"chastises\",\n",
    "    \"chastising\", \"chauvinism\", \"chauvinist\", \"chauvinistic\", \"cheat\", \"cheats\", \"cheated\",\n",
    "    \"cheating\", \"commend\", \"commended\", \"commends\", \"commending\", \"competence\",\n",
    "    \"competent\", \"conceit\", \"conceited\", \"connive\", \"connived\", \"connives\", \"conniving\",\n",
    "    \"conscience\", \"contemptible\", \"contemptibly\", \"corrupt\", \"corrupted\", \"corrupting\",\n",
    "    \"corruption\", \"courage\", \"courageous\", \"craven\", \"criminal\", \"criminals\", \"crook\",\n",
    "    \"crooks\", \"cruel\", \"crueler\", \"cruelest\", \"crueller\", \"cruellest\", \"cruelly\",\n",
    "    \"cruelties\", \"cruelty\", \"debauch\", \"debauched\", \"debauches\", \"debauching\", \"decadence\",\n",
    "    \"decadent\", \"deceive\", \"deceived\", \"deceives\", \"deceiving\", \"decency\", \"decent\",\n",
    "    \"decently\", \"deceptive\", \"deceptively\", \"delinquent\", \"delinquency\", \"deprave\",\n",
    "    \"depraved\", \"depraves\", \"depraving\", \"deserve\", \"deserved\", \"deserves\", \"deserving\",\n",
    "    \"despicable\", \"deviant\", \"deviants\", \"dignified\", \"dignity\", \"disapprove\",\n",
    "    \"disapproved\", \"disapproves\", \"disapproving\", \"disgrace\", \"disgraced\", \"disgraces\",\n",
    "    \"disgracing\", \"dishonest\", \"dishonesty\", \"dishonor\", \"dishonored\", \"dishonorable\",\n",
    "    \"dishonourable\", \"disloyal\", \"disrespect\", \"disrespected\", \"disrespecting\",\n",
    "    \"disrespectful\", \"diss\", \"dissed\", \"dissing\", \"dumb\", \"dutiful\", \"duty\", \"elitism\",\n",
    "    \"elitist\", \"elitists\", \"equality\", \"equitable\", \"ethic\", \"ethical\", \"ethics\", \"evil\",\n",
    "    \"evildoer\", \"evildoers\", \"excuse\", \"excuses\", \"excused\", \"excusing\", \"fairness\",\n",
    "    \"faithful\", \"faithless\", \"fake\", \"fakes\", \"faking\", \"fatass\", \"fatso\", \"fatties\",\n",
    "    \"forgive\", \"forgiven\", \"forgives\", \"forgiving\", \"foul\", \"fouled\", \"fouling\", \"fraud\",\n",
    "    \"frauds\", \"fraudulent\", \"generosity\", \"generous\", \"glutton\", \"gluttony\", \"godless\",\n",
    "    \"godlessness\", \"grandiose\", \"greed\", \"greedy\", \"hateful\", \"haters\", \"heathen\",\n",
    "    \"heathens\", \"hero\", \"heroes\", \"heroic\", \"heroine\", \"heroines\", \"hideous\", \"hideously\",\n",
    "    \"homily\", \"fault\", \"faults\", \"faulted\", \"faulting\", \"honest\", \"honesty\", \"honor\",\n",
    "    \"honored\", \"honoring\", \"honorable\", \"honour\", \"horrid\", \"horridly\", \"humane\",\n",
    "    \"humanitarian\", \"hypocrisy\", \"hypocrite\", \"hypocrites\", \"ideal\", \"ideals\", \"ideologue\",\n",
    "    \"ignoble\", \"ignorant\", \"immodest\", \"immoral\", \"immorality\", \"inappropriate\",\n",
    "    \"inconsiderate\", \"incorruptible\", \"indecency\", \"indecent\", \"indignantly\", \"inequity\",\n",
    "    \"infallible\", \"infidel\", \"infidels\", \"infidelity\", \"inhumane\", \"iniquity\", \"injustice\",\n",
    "    \"innocence\", \"innocent\", \"innocently\", \"irresponsible\", \"judge\", \"judged\", \"judges\",\n",
    "    \"judging\", \"judgy\", \"justice\", \"justness\", \"kosher\", \"laughingstock\", \"lawless\",\n",
    "    \"lawlessness\", \"lazier\", \"laziest\", \"laziness\", \"lazy\", \"lecherous\", \"lewd\", \"liar\",\n",
    "    \"liars\", \"lousy\", \"loyal\", \"magnanimity\", \"magnanimous\", \"mansplain\", \"misbehave\",\n",
    "    \"misbehaved\", \"misbehaving\", \"misconduct\", \"miser\", \"miserly\", \"misogynist\",\n",
    "    \"misogynistic\", \"mistreat\", \"mistreated\", \"mistreating\", \"misuse\", \"misused\",\n",
    "    \"misuses\", \"misusing\", \"molest\", \"molested\", \"molesting\", \"moral\", \"morality\",\n",
    "    \"nefarious\", \"nerd\", \"nerds\", \"nerdy\", \"noble\", \"obstinate\", \"offensive\",\n",
    "    \"opinionated\", \"outlaw\", \"outlawed\", \"outlawing\", \"outrageous\", \"overbearing\",\n",
    "    \"overconfident\", \"pariah\", \"patriot\", \"patriots\", \"pedophile\", \"penance\", \"penitent\",\n",
    "    \"perv\", \"pervert\", \"perverted\", \"perverts\", \"pervy\", \"pettier\", \"pettiest\", \"pettily\",\n",
    "    \"pettiness\", \"petty\", \"phony\", \"pitiful\", \"pitifully\", \"plagiarize\", \"prejudice\",\n",
    "    \"principled\", \"promiscuity\", \"promiscuous\", \"prude\", \"prudish\", \"psycho\", \"puny\",\n",
    "    \"pussies\", \"racist\", \"rapist\", \"rectitude\", \"redneck\", \"reprehensible\", \"repulsive\",\n",
    "    \"revolting\", \"revoltingly\", \"ridicule\", \"ridiculous\", \"ridiculously\", \"righteous\",\n",
    "    \"righteously\", \"ruthless\", \"scandal\", \"scandals\", \"scruples\", \"scrupulous\", \"scum\",\n",
    "    \"selfish\", \"selflessness\", \"sexism\", \"sexist\", \"shame\", \"shamed\", \"shaming\", \"sin\",\n",
    "    \"sincere\", \"sincerity\", \"sinful\", \"sinfully\", \"sinister\", \"sinned\", \"sinner\", \"sinners\",\n",
    "    \"sins\", \"sissies\", \"sissy\", \"skank\", \"slander\", \"slandered\", \"slandering\", \"slimy\",\n",
    "    \"slothful\", \"slut\", \"sluts\", \"slutty\", \"smug\", \"sneakily\", \"sneaky\", \"snide\",\n",
    "    \"snidely\", \"snob\", \"snobs\", \"spineless\", \"thief\", \"thieves\", \"traitor\", \"transgress\",\n",
    "    \"treacherous\", \"treason\", \"trustworthy\", \"trusty\", \"truthful\", \"truthfully\",\n",
    "    \"unacceptable\", \"unethical\", \"unfair\", \"unfaithful\", \"ungodly\", \"ungracious\", \"unjust\",\n",
    "    \"unloyal\", \"unpatriotic\", \"unprincipled\", \"unqualified\", \"unreasonable\", \"unsavory\",\n",
    "    \"unscrupulous\", \"unselfish\", \"untrustworthy\", \"unvirtuous\", \"unworthy\", \"upstanding\",\n",
    "    \"useful\", \"useless\", \"vain\", \"vainly\", \"vanity\", \"vengeance\", \"vile\", \"vilify\",\n",
    "    \"vindicate\", \"virtue\", \"virtuous\", \"wanton\", \"wicked\", \"worthless\", \"worthwhile\",\n",
    "    \"worthy\", \"wrong\", \"wrongdoing\", \"wronged\", \"wrongful\", \"wrongly\", \"zealot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moral_words(text):\n",
    "    '''\n",
    "    Tokenizes text into list of words and keeps only those from the LIWC\n",
    "    dictionary\n",
    "\n",
    "    Inputs:\n",
    "      - text (str): cleaned text from subreddit\n",
    "\n",
    "    Outputs:\n",
    "      (list): list of LIWC words\n",
    "    '''\n",
    "    words_liwc = []\n",
    "\n",
    "    words = text.split()\n",
    "\n",
    "    for word in words:\n",
    "        if word in liwc_moral:\n",
    "            words_liwc.append(word)\n",
    "\n",
    "    return words_liwc\n",
    "\n",
    "def count_words(data):\n",
    "    '''\n",
    "    Create a dictionary that maps moral words with their frequency on the entire\n",
    "    corpus\n",
    "\n",
    "    Inputs:\n",
    "      - data (series): cleaned_text column\n",
    "\n",
    "    Outputs:\n",
    "      - (dict): dictionary mapping words with their frequencies\n",
    "\n",
    "    '''\n",
    "\n",
    "    moral_words_counts = {}\n",
    "\n",
    "    for entry in data:\n",
    "        row_words = get_moral_words(entry)\n",
    "\n",
    "        for word in row_words:\n",
    "            moral_words_counts[word] = moral_words_counts.get(word, 0) + 1\n",
    "\n",
    "    #I asked ChatGPT how to sort by value\n",
    "\n",
    "    sorted_dict= dict(sorted(moral_words_counts.items(), key=lambda item: item[1],\n",
    "                                                                  reverse=True))\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "moral_dict = count_words(selfimprovement[\"cleaned_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "selfimprovement2[\"moral_words\"] = selfimprovement2[\"cleaned_text\"].apply(lambda x: get_moral_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get average positive emotion and negative emotion scores for top 15 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_emotion(df, moral_dict):\n",
    "    avg_pos_emotion = {}\n",
    "    avg_neg_emotion = {}\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        for word in row[\"moral_words\"]:\n",
    "            avg_pos_emotion[word] = avg_pos_emotion.get(word, 0) + row[\"emo_pos\"]\n",
    "            avg_neg_emotion[word] = avg_neg_emotion.get(word, 0) + row[\"emo_neg\"]\n",
    "\n",
    "    for word, value in avg_pos_emotion.items():\n",
    "        avg_pos_emotion[word] = value / moral_dict[word]\n",
    "\n",
    "    for word, value in avg_neg_emotion.items():\n",
    "        avg_neg_emotion[word] = value / moral_dict[word]\n",
    "\n",
    "    return avg_pos_emotion, avg_neg_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pos, avg_neg = get_avg_emotion(selfimprovement2, moral_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emotion_df(avg_pos_emotion, avg_neg_emotion, moral_dict):\n",
    "    # Create a dictionary with words as keys and their corresponding pos, neg scores and counts as values\n",
    "    data = {\n",
    "        'word': list(avg_pos_emotion.keys()),\n",
    "        'count': [moral_dict.get(word, 0) for word in avg_pos_emotion],  # Use moral_dict to get word count\n",
    "        'pos_score': [avg_pos_emotion.get(word, 0) for word in avg_pos_emotion],\n",
    "        'neg_score': [avg_neg_emotion.get(word, 0) for word in avg_neg_emotion]\n",
    "    }\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>forgive</td>\n",
       "      <td>6151</td>\n",
       "      <td>1.089117</td>\n",
       "      <td>1.488629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>useful</td>\n",
       "      <td>7870</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>0.772639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>judging</td>\n",
       "      <td>3278</td>\n",
       "      <td>1.027117</td>\n",
       "      <td>1.155918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>generous</td>\n",
       "      <td>604</td>\n",
       "      <td>1.464520</td>\n",
       "      <td>0.804023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loyal</td>\n",
       "      <td>523</td>\n",
       "      <td>1.380096</td>\n",
       "      <td>1.049235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>depraves</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>deprave</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>cruellest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>1.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>adulterer</td>\n",
       "      <td>1</td>\n",
       "      <td>2.060000</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>godlessness</td>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>427 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  count  pos_score  neg_score\n",
       "0        forgive   6151   1.089117   1.488629\n",
       "1         useful   7870   0.985366   0.772639\n",
       "2        judging   3278   1.027117   1.155918\n",
       "3       generous    604   1.464520   0.804023\n",
       "4          loyal    523   1.380096   1.049235\n",
       "..           ...    ...        ...        ...\n",
       "422     depraves      1   0.000000   1.350000\n",
       "423      deprave      1   0.980000   1.950000\n",
       "424    cruellest      1   0.820000   1.640000\n",
       "425    adulterer      1   2.060000   1.030000\n",
       "426  godlessness      1   0.830000   1.000000\n",
       "\n",
       "[427 rows x 4 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_moral_words = create_emotion_df(avg_pos, avg_neg, moral_dict)\n",
    "df_moral_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a combined emotional score by substracting the negative score from the positive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moral_words[\"overall_emo\"] = df_moral_words[\"pos_score\"] - df_moral_words[\"neg_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_moral_words.to_csv(\"datavis/moral_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensure correct parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_moral_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m saved_csv \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mdatavis/moral_words.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(df_moral_words\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(saved_csv\u001b[39m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_moral_words' is not defined"
     ]
    }
   ],
   "source": [
    "saved_csv = pd.read_csv(\"datavis/moral_words.csv\")\n",
    "\n",
    "print(df_moral_words.shape)\n",
    "print(saved_csv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
